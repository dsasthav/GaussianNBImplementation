{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I utilize my own implementation of the Gaussian Naive Bayes classifier and compare it to the performance of the implementation in sklearn. I will only test the performance on one dataset, Diabetes.csv. The purpose of this dataset is to predict whether or not someone has diabetes given 8 different medical attributes (all numeric) about them. My implementation only predicts classes, it does not compute probabilities for each instance. This is a feature that will be implemented in future iterations. I discuss more about improvements at the bottom of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the data and the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import my implementation\n",
    "from myGaussianNB import myGaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bring in the opposition\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the necessary objects\n",
    "\n",
    "myGNB = myGaussianNB() # mine\n",
    "\n",
    "gnb = GaussianNB() #sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumberPregnant  GlucoseConcentration  BloodPressure  SkinThickness  \\\n",
      "0               6                   148             72             35   \n",
      "1               1                    85             66             29   \n",
      "2               8                   183             64              0   \n",
      "3               1                    89             66             23   \n",
      "4               0                   137             40             35   \n",
      "\n",
      "   Insulin   BMI  DPFunction  Age  Class  \n",
      "0        0  33.6       0.627   50      1  \n",
      "1        0  26.6       0.351   31      0  \n",
      "2        0  23.3       0.672   32      1  \n",
      "3       94  28.1       0.167   21      0  \n",
      "4      168  43.1       2.288   33      1  \n"
     ]
    }
   ],
   "source": [
    "# Read in the data\n",
    "from pandas import read_csv\n",
    "df = read_csv(\"Diabetes.csv\")\n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is already clean and numeric. No cleaning or processing necessary which is obviously a huge simplifying assumption for my implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up the data for training and testing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "target = \"Class\"\n",
    "\n",
    "train, test = train_test_split(df, test_size = 0.1)\n",
    "X_train = train.ix[:, train.columns != target]\n",
    "X_test = test.ix[:,test.columns != target]\n",
    "Y_train = train[target]\n",
    "Y_test = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit each model to the data\n",
    "myGNB.fit(train,\"Class\")\n",
    "gnb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_preds = myGNB.predict(X_test)\n",
    "preds = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My performance: \n",
      "[[42  4]\n",
      " [18 13]]\n",
      "\n",
      "Sklearn performance: \n",
      "[[42  4]\n",
      " [18 13]]\n"
     ]
    }
   ],
   "source": [
    "# Check confusion matrices\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print \"My performance: \"\n",
    "print confusion_matrix(Y_test, my_preds)\n",
    "print \n",
    "print \"Sklearn performance: \"\n",
    "print confusion_matrix(Y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly enough, they output the same confusion matrix, meaning they most likely classified each instance the same. So, that means they should have the same precision, recall, and accuracy scores as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Accuracy: 0.7143 \n",
      "Sklearn Accuracy: 0.7143 \n",
      "My Precision: 0.4194\n",
      "Sklearn Precision: 0.4194\n",
      "My Recall: 0.7647\n",
      "Sklearn Recall: 0.7647\n"
     ]
    }
   ],
   "source": [
    "# Compare overall accuracy, precision, and recall\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print \"My Accuracy: %.4f \" % accuracy_score(Y_test, my_preds)\n",
    "print \"Sklearn Accuracy: %.4f \" % accuracy_score(Y_test, preds)\n",
    "print \"My Precision: %.4f\" % recall_score(Y_test, my_preds)\n",
    "print \"Sklearn Precision: %.4f\" % recall_score(Y_test, preds)\n",
    "print \"My Recall: %.4f\" % precision_score(Y_test, my_preds)\n",
    "print \"Sklearn Recall: %.4f\" % precision_score(Y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe this is a function of the one train/test split. Maybe, if we try it more times, they will yield different performances for different train/test splits. I'll try running some simulations to see who ultimately gets the better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run 1000 simulations to see who is better in the long run\n",
    "# Syntax: 1 if I win, 0 if Sklearn wins\n",
    "\n",
    "winner = [0] * 1000\n",
    "for i in range(1000):\n",
    "    train, test = train_test_split(df, test_size = 0.1)\n",
    "    X_train = train.ix[:, train.columns != target]\n",
    "    X_test = test.ix[:,test.columns != target]\n",
    "    Y_train = train[target]\n",
    "    Y_test = test[target]\n",
    "    myGNB.fit(train,\"Class\")\n",
    "    gnb.fit(X_train, Y_train)\n",
    "    my_preds = myGNB.predict(X_test)\n",
    "    preds = gnb.predict(X_test)\n",
    "    my_accuracy = accuracy_score(Y_test, my_preds)\n",
    "    sk_accuracy = accuracy_score(Y_test, preds)\n",
    "    if my_accuracy > sk_accuracy:\n",
    "        winner[i] = 1\n",
    "    elif my_accuracy < sk_accuracy:\n",
    "        winner[i] = -1\n",
    "    else: \n",
    "        winner[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e6adea557c66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mwinner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwinner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwinner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"bar\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "winner = pd.Series(winner)\n",
    "vals = winner.value_counts()\n",
    "vals.plot(kind = \"bar\")\n",
    "plt.title(\"Who's implementation is better?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Literally all 1000 had the same exacy accuracy. This means either I did something wrong in the code somewhere or my algorithm just classifies each instance the same because it is basically the same algorithm. I am pretty skeptical about my algorithm producing the exact same results, but I am just going to accept it for now because I completed my goal of implementing Naive Bayes Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was definitely a valuable learning experience to try to write a classification algorithm from scratch. Here are some of the things I learned:\n",
    "\n",
    "1. How to implement a python class and use it in your own code\n",
    "2. How to modularize the code and break the class into smaller functions\n",
    "3. How the Naive Bayes algorithm works in practice\n",
    "4. The different components necessary for a supervised learning object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I have more time in the future to come back to this, here is what I would work on:\n",
    "\n",
    "1. Implementing the function to predict probabilities instead of just classes.This would allow me to create an ROC Curve and calculate AUC. This would probably let me find the true distinction between my implementation and that of SKlearn.\n",
    "2. Testing on different data sets\n",
    "3. Implementing more features such as error handling. Right now, my data set has to be perfctly clean (all numerics) to use. In an ideal world, my class would be able to clean, transform, and process the data automatically and put it in the right form for modeling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
